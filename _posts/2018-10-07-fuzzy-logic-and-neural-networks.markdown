---
layout: post
title:  "Нечеткие логики и нейронные сети"
date:   2018-10-07 14:02:54 +0300
categories: jekyll update
author: Teman Zampano
---


![Изображение нейронной сети](/assets/nn.png)

Каждая разновидность систем искусственного интеллекта имеет свои особенности, например, по возможностям обучения, обобщения и выработки выводов, что делает ее наиболее пригодной для решения одного класса задач и менее пригодной — для другого.

Например, нейронные сети хороши для задач распознавания образов, но весьма неудобны для выяснения вопроса, как они такое распознавание осуществляют. Они могут автоматически приобретать знания, но процесс их обучения зачастую происходит достаточно медленно, а анализ обученной сети весьма сложен (обученная сеть обычно — черный ящик для пользователя). При этом какую-либо априорную информацию (знания эксперта) для ускорения процесса ее обучения в нейронную сеть ввести невозможно.

Системы с нечеткой логикой, напротив, хороши для объяснения получаемых с их помощью выводов, но они не могут автоматически приобретать знания для использования их в механизмах выводов. Необходимость разбиения универсальных множеств на отдельные области, как правило, ограничивает количество входных переменных в таких системах небольшим значением.

Вообще говоря, теоретически, системы с нечеткой логикой и искусственные нейронные сети эквивалентны друг другу, однако, в соответствии с изложенным выше, на практике у них имеются свои собственные достоинства и недостатки. Данное соображение легло в основу аппарата гибридных сетей, в которых выводы делаются на основе аппарата нечеткой логики, но соответствующие функции принадлежности подстраиваются с использованием алгоритмов обучения нейронных сетей, например, алгоритма обратного распространения ошибки. Такие системы не только используют априорную информацию, но могут приобретать новые знания и для пользователя являются логически прозрачными.

# ** Основные понятия гибридных нейронных сетей ** 

Для пояснения сущности гибридных сетей, рассмотрим еще раз простую нейронную сеть, имеющую два входа и только один нейрон (выше на рисунке).

Здесь входные сигналы xi «взаимодействуют» с весами ωi, образуя произведения

>pi = xi*ωi, i=1,2


Такая частная информация (произведения) объединяются с ис­пользованием операции суммирования, образуя вход net-нейрона (нейрона сети) :
>net = p1 + p2 = ω1x1 + ω2x2

Выход нейрона образуется в результате преобразования входа netнекоторой активационной функцией:

>у = f(net) = f(ω1x1 + ω2x2) 

например, сигмоидного типа

![Функция сигмоидного типа](/assets/sigmoid.jpg)

Приведенную однонейронную сеть, в которой используются опе­рации умножения, суммирования и сигмоидная функция актива­ции, будем называть стандартной нейронной сетью.

![Стандартная нейронная есть](/assets/standard_nn.jpg)

В случае применения других операций, таких как t-норма или t-конорма, придем к нейронной сети, которая будет называться гибридной.

**Определение.** 

>Гибридная нейронная сеть — это нейронная сеть с четкими сигналами, весами и активационной функцией, но с объединением xi и ωi, p1 и р2 с использованием t-нормы, t-конормы или некоторых других непрерывных операций.

Входы, выходы и веса гибридной нейронной сети — веществен­ные числа, принадлежащие отрезку [0, 1].

Рассмотрим следующие примеры элементарных гибридных ней­ронных сетей.

*Нечеткий нейрон «И».* Сигналы xi и веса ωi в данном случае объединяются с помощью треугольной конормы:

>pt = S(ωi, xi), i = 1,2,

а выход образуется с применением треугольной нормы:

>у = AND(p1,р2) = Т(p1,р2) = Т(S(ω1, x1), S(ω2, x2) ).

Если принять T= min, S = max, тогда нечеткий нейрон «И» реализует композицию min-max:

>у=min (ω1˅ x1 , ω2˅ x2).

**Вид нечеткого нейрона "И":**

![Вид нейрона](/assets/and_neuron.jpg)


*Нечеткий нейрон «ИЛИ».* Сигналы xi и веса ωi здесь объ­единяются с помощью треугольной нормы:

>Pi = T(ωi, xi), i = 1,2,

а выход образуется с применением треугольной конормы:

>у = OR(p1,p2) = S(p1 ,p2) = S(T(ω1, х1), T(ω2, х2).

Если принять Т = min, S= max, тогда нечеткий нейрон «ИЛИ» реализует композицию max-min:

>у=max (ω1˄ x1 , ω2˄ x2).

**Вид нечеткого нейрона "ИЛИ"**

![Вид другого нейрона](/assets/or_neuron.jpg)



[Назад](https://exploder747.github.io/)
